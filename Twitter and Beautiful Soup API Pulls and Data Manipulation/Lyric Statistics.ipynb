{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the twitter section\n",
    "import tweepy\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "from pprint import pprint\n",
    "import shutil\n",
    "\n",
    "# for the lyrics scrape section\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict, Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = {'eminem':\"https://www.azlyrics.com/e/eminem.html\",\n",
    "           'fiddy':\"https://www.azlyrics.com/19/50cent.html\"} \n",
    "# we'll use this dictionary to hold both the artist name and the link on AZlyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping eminem\n",
      "Done Scraping eminem\n",
      "Scraping fiddy\n",
      "Done Scraping fiddy\n"
     ]
    }
   ],
   "source": [
    "# Let's set up a dictionary of lists to hold our links\n",
    "lyrics_pages = defaultdict(list)\n",
    "\n",
    "for artist, artist_page in artists.items() :\n",
    "    print(f'Scraping {artist}')\n",
    "    # request the page and sleep\n",
    "    r = requests.get(artist_page)\n",
    "    time.sleep(5 + 10*random.random())\n",
    "    \n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "    lyric_divs = soup.find_all(\"div\", class_=\"listalbum-item\")\n",
    "\n",
    "    lyric_urls = []\n",
    "\n",
    "    for ld in lyric_divs[:20]:\n",
    "        this_anchor = ld.find('a')\n",
    "        lyric_urls+=['https://www.azlyrics.com'+this_anchor['href']]\n",
    "\n",
    "    lyrics_pages[artist]=lyric_urls\n",
    "    print(f'Done Scraping {artist}')\n",
    "    # now extract the links to lyrics pages from this page\n",
    "    # store the links `lyrics_pages` where the key is the artist and the\n",
    "    # value is a list of links. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'eminem': ['https://www.azlyrics.com/lyrics/eminem/infinite.html', 'https://www.azlyrics.com/lyrics/eminem/wegointerlude.html', 'https://www.azlyrics.com/lyrics/eminem/itsok.html', 'https://www.azlyrics.com/lyrics/eminem/313.html', 'https://www.azlyrics.com/lyrics/eminem/tonight.html', 'https://www.azlyrics.com/lyrics/eminem/maxine.html', 'https://www.azlyrics.com/lyrics/eminem/openmic.html', 'https://www.azlyrics.com/lyrics/eminem/never2far.html', 'https://www.azlyrics.com/lyrics/eminem/searchin.html', 'https://www.azlyrics.com/lyrics/eminem/backstabber.html', 'https://www.azlyrics.com/lyrics/eminem/jealousywoesii.html', 'https://www.azlyrics.com/lyrics/eminem/introslimshady.html', 'https://www.azlyrics.com/lyrics/eminem/lowdowndirty.html', 'https://www.azlyrics.com/lyrics/eminem/ifihad.html', 'https://www.azlyrics.com/lyrics/eminem/justdontgiveafuck.html', 'https://www.azlyrics.com/lyrics/eminem/mommyskit.html', 'https://www.azlyrics.com/lyrics/eminem/justthetwoofus.html', 'https://www.azlyrics.com/lyrics/eminem/noonesillerthanme.html', 'https://www.azlyrics.com/lyrics/eminem/murdermurder.html', 'https://www.azlyrics.com/lyrics/eminem/publicserviceannouncementskit.html'], 'fiddy': ['https://www.azlyrics.com/lyrics/50cent/thehit.html', 'https://www.azlyrics.com/lyrics/50cent/thegooddieyoung.html', 'https://www.azlyrics.com/lyrics/50cent/cornerbodega.html', 'https://www.azlyrics.com/lyrics/50cent/lifesontheline.html', 'https://www.azlyrics.com/lyrics/50cent/thataintgangsta.html', 'https://www.azlyrics.com/lyrics/50cent/astheworldturns.html', 'https://www.azlyrics.com/lyrics/50cent/ghettoquranforgivemept1.html', 'https://www.azlyrics.com/lyrics/50cent/darepercussions.html', 'https://www.azlyrics.com/lyrics/50cent/makemoneybyanymeans.html', 'https://www.azlyrics.com/lyrics/50cent/materialgirl2000.html', 'https://www.azlyrics.com/lyrics/50cent/thuglove.html', 'https://www.azlyrics.com/lyrics/50cent/slowdough.html', 'https://www.azlyrics.com/lyrics/50cent/gunrunners.html', 'https://www.azlyrics.com/lyrics/50cent/youaintnogangsta.html', 'https://www.azlyrics.com/lyrics/50cent/powerofthedollar.html', 'https://www.azlyrics.com/lyrics/50cent/imahustler.html', 'https://www.azlyrics.com/lyrics/50cent/howtorob.html', 'https://www.azlyrics.com/lyrics/50cent/ushouldbehere.html', 'https://www.azlyrics.com/lyrics/50cent/bumpdatstreetmix.html', 'https://www.azlyrics.com/lyrics/50cent/banksworkout.html']})\n"
     ]
    }
   ],
   "source": [
    "print(lyrics_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For eminem we have 20.\n",
      "The full pull will take for this artist will take 0.06 hours.\n",
      "For fiddy we have 20.\n",
      "The full pull will take for this artist will take 0.06 hours.\n"
     ]
    }
   ],
   "source": [
    "# Let's see how long it's going to take to pull these lyrics \n",
    "# if we're waiting `5 + 10*random.random()` seconds \n",
    "for artist, links in lyrics_pages.items() : \n",
    "    print(f\"For {artist} we have {len(links)}.\")\n",
    "    print(f\"The full pull will take for this artist will take {round(len(links)*10/3600,2)} hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filename_from_link(link) :\n",
    "    \n",
    "    if not link :\n",
    "        return None\n",
    "    \n",
    "    # drop the http or https and the html\n",
    "    name = link.replace(\"https\",\"\").replace(\"http\",\"\")\n",
    "    name = link.replace(\".html\",\"\")\n",
    "\n",
    "    name = name.replace(\"/lyrics/\",\"\")\n",
    "    \n",
    "    # Replace useless chareacters with UNDERSCORE\n",
    "    name = name.replace(\"://\",\"\").replace(\".\",\"_\").replace(\"/\",\"_\")\n",
    "    \n",
    "    # tack on .txt\n",
    "    name = name + \".txt\"\n",
    "    \n",
    "    return(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the lyrics folder here. If you'd like to practice your programming, add functionality \n",
    "# that checks to see if the folder exists. If it does, then use shutil.rmtree to remove it and create a new one.\n",
    "\n",
    "if os.path.isdir(\"lyrics/\") : \n",
    "    shutil.rmtree(\"lyrics/\")\n",
    "\n",
    "os.mkdir(\"lyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_stub = \"https://www.azlyrics.com\" \n",
    "start = time.time()\n",
    "\n",
    "total_pages = 0 \n",
    "\n",
    "for artist in lyrics_pages :\n",
    "    pass\n",
    "    # Use this space to carry out the following steps: \n",
    "    \n",
    "    # 1. Build a subfolder for the artist\n",
    "    if os.path.isdir(f\"lyrics/{artist}\") : \n",
    "        shutil.rmtree(f\"lyrics/{artist}\")\n",
    "\n",
    "    os.mkdir(f\"lyrics/{artist}\")\n",
    "\n",
    "    # 2. Iterate over the lyrics pages (20)\n",
    "\n",
    "    for page in lyrics_pages[artist][:20]:\n",
    "    \n",
    "    # 3. Request the lyrics page. \n",
    "\n",
    "        r = requests.get(page)\n",
    "        time.sleep(5 + 10*random.random())\n",
    "\n",
    "    # 4. Extract the title and lyrics from the page.\n",
    "\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "    # 4. Extract the title and lyrics from the page.\n",
    "\n",
    "        title = str(soup.title.string).split(\"Lyrics\")[0] # Get lyrics names from pagetitle\n",
    "\n",
    "        divs = soup.find_all(\"div\")\n",
    "\n",
    "        lyrics = ''\n",
    "\n",
    "        for div in divs:\n",
    "            for c in div.contents:\n",
    "                if \"Usage of azlyrics.com\" in c:\n",
    "                    lyrics = (div.text)\n",
    "                    break\n",
    "\n",
    "        filename = generate_filename_from_link(page)\n",
    "        with open(os.path.join('.','lyrics',artist,filename), 'w') as f:\n",
    "            f.write(title)\n",
    "            # already two spaces but this will write two spaces: f.write('\\n\\n')\n",
    "            f.write(lyrics)\n",
    "        \n",
    "\n",
    "    # 5. Write out the title, two returns ('\\n'), and the lyrics. Use `generate_filename_from_url`\n",
    "    #    to generate the filename. \n",
    "    \n",
    "    # Remember to pull at least 20 songs per artist. It may be fun to pull all the songs for the artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total run time was 0.12 hours.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total run time was {round((time.time() - start)/3600,2)} hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For eminem we have 20 files.\n",
      "For eminem we have roughly 13425 words, 2518 are unique.\n",
      "For fiddy we have 20 files.\n",
      "For fiddy we have roughly 14519 words, 2107 are unique.\n"
     ]
    }
   ],
   "source": [
    "## Validation\n",
    "\n",
    "def words(text): \n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "artist_folders = os.listdir(\"lyrics/\")\n",
    "artist_folders = [f for f in artist_folders if os.path.isdir(\"lyrics/\" + f)]\n",
    "\n",
    "for artist in artist_folders : \n",
    "    artist_files = os.listdir(\"lyrics/\" + artist)\n",
    "    artist_files = [f for f in artist_files if 'txt' in f or 'csv' in f or 'tsv' in f]\n",
    "\n",
    "    print(f\"For {artist} we have {len(artist_files)} files.\")\n",
    "\n",
    "    artist_words = []\n",
    "\n",
    "    for f_name in artist_files : \n",
    "        with open(\"lyrics/\" + artist + \"/\" + f_name) as infile : \n",
    "            artist_words.extend(words(infile.read()))\n",
    "\n",
    "            \n",
    "    print(f\"For {artist} we have roughly {len(artist_words)} words, {len(set(artist_words))} are unique.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c21f4b550d44dd8da30efeda0f3fb842b1394f99ed710ddf513c5093383f4f73"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
